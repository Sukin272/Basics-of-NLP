{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ansh/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "dataset=datasets.load_dataset(\"PiC/phrase_similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_score(word1, word2):\n",
    "    if word1 not in wv or word2 not in wv:\n",
    "        return 0\n",
    "    return wv.similarity(word1, word2)\n",
    "\n",
    "def sentencesToMatrix(sentence1, sentence2):\n",
    "    lis1 = sentence1.split()\n",
    "    lis2 = sentence2.split()\n",
    "    simMatrix=[]\n",
    "    for i in lis1:\n",
    "        if i not in wv:\n",
    "            continue\n",
    "        temp=[]\n",
    "        for j in lis2:\n",
    "            if j not in wv:\n",
    "                continue\n",
    "            temp.append(similarity_score(i,j))\n",
    "        simMatrix.append(temp)\n",
    "    return simMatrix\n",
    "\n",
    "def biggestColumn(matrix):\n",
    "    maxCol=[]\n",
    "    for i in matrix:\n",
    "        i.append(0)\n",
    "        maxCol.append(max([a for a in i if a<0.95]))\n",
    "    return maxCol\n",
    "\n",
    "## BERTSCORE\n",
    "def getSentenceScore(sentence1, sentence2):\n",
    "    sentence1=sentence1.lower()\n",
    "    sentence2=sentence2.lower()\n",
    "    simMatrix = sentencesToMatrix(sentence1, sentence2)\n",
    "    maxCol = biggestColumn(simMatrix)\n",
    "    return sum(maxCol)/len(maxCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "air position\n",
      "posture while jumping\n",
      "0.29195863753557205\n",
      "0\n",
      "\n",
      "associated track\n",
      "correlating music single\n",
      "0.3045092970132828\n",
      "0\n",
      "\n",
      "whole parts\n",
      "extended sections\n",
      "0.340593621134758\n",
      "1\n",
      "\n",
      "wide set\n",
      "spacious collection\n",
      "0.17399294674396515\n",
      "0\n",
      "\n",
      "full protection\n",
      "complete defense\n",
      "0.35668858140707016\n",
      "0\n",
      "\n",
      "prior case\n",
      "preceding game\n",
      "0.46622487902641296\n",
      "0\n",
      "\n",
      "another station\n",
      "a separate airport\n",
      "0.2849593162536621\n",
      "0\n",
      "\n",
      "initial activity\n",
      "starting task\n",
      "0.12714136019349098\n",
      "1\n",
      "\n",
      "single square\n",
      "solitary border\n",
      "0.21403459459543228\n",
      "1\n",
      "\n",
      "independent operation\n",
      "individual enterprise\n",
      "0.22330620139837265\n",
      "0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cur='test'\n",
    "for i in range(10):\n",
    "    print(dataset[cur][i]['phrase1'])\n",
    "    print(dataset[cur][i]['phrase2'])\n",
    "    print(getSentenceScore(dataset[cur][i]['phrase1'], dataset[cur][i]['phrase2']))\n",
    "    print(dataset[cur][i]['label'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5125\n"
     ]
    }
   ],
   "source": [
    "threshold=0.4\n",
    "correct=0\n",
    "cur='test'\n",
    "for i in range(len(dataset[cur])):\n",
    "    if getSentenceScore(dataset[cur][i]['phrase1'], dataset[cur][i]['phrase2'])>threshold:\n",
    "        if dataset[cur][i]['label']==1:\n",
    "            correct+=1\n",
    "    else:\n",
    "        if dataset[cur][i]['label']==0:\n",
    "            correct+=1\n",
    "print(correct/len(dataset[cur]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
