{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ansh/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "dataset=datasets.load_dataset(\"paws\", \"labeled_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer, BertModel\n",
    "# import torch\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertModel.from_pretrained('bert-base-uncased')\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# model.to(device)\n",
    "\n",
    "# def similarity_score(word1, word2):\n",
    "#     encoded_word1 = tokenizer(word1, return_tensors='pt', padding=True, truncation=True)\n",
    "#     encoded_word2 = tokenizer(word2, return_tensors='pt', padding=True, truncation=True)\n",
    "#     encoded_word1.to(device)\n",
    "#     encoded_word2.to(device)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         output1 = model(**encoded_word1)\n",
    "#         output2 = model(**encoded_word2)\n",
    "    \n",
    "\n",
    "#     embedding1 = output1.last_hidden_state.mean(dim=1).squeeze(0)\n",
    "#     embedding2 = output2.last_hidden_state.mean(dim=1).squeeze(0)\n",
    "    \n",
    "#     embedding1 /= torch.norm(embedding1, dim=-1, keepdim=True)\n",
    "#     embedding2 /= torch.norm(embedding2, dim=-1, keepdim=True)\n",
    "\n",
    "#     sim_score = cosine_similarity(embedding1.reshape(1, -1), embedding2.reshape(1, -1))\n",
    "\n",
    "#     return sim_score[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_score(word1, word2):\n",
    "    if word1 not in wv or word2 not in wv:\n",
    "        return 0\n",
    "    return wv.similarity(word1, word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9425530127497206\n",
      "0.9792997443616231\n",
      "0.23887685987189416\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine, cdist\n",
    "import numpy as np\n",
    "\n",
    "def sentencesToMatrix(sentence1, sentence2):\n",
    "    lis1 = sentence1.split()\n",
    "    lis2 = sentence2.split()\n",
    "    simMatrix=[]\n",
    "    for i in lis1:\n",
    "        if i not in wv:\n",
    "            continue\n",
    "        temp=[]\n",
    "        for j in lis2:\n",
    "            if j not in wv:\n",
    "                continue\n",
    "            temp.append(similarity_score(i,j))\n",
    "        simMatrix.append(temp)\n",
    "    return simMatrix\n",
    "\n",
    "def biggestColumn(matrix):\n",
    "    maxCol=[]\n",
    "    for i in matrix:\n",
    "        maxCol.append(max(i))\n",
    "    return maxCol\n",
    "\n",
    "## BERTSCORE\n",
    "def executeBertScore(sentence1, sentence2):\n",
    "    sentence1=sentence1.lower()\n",
    "    sentence2=sentence2.lower()\n",
    "    simMatrix = sentencesToMatrix(sentence1, sentence2)\n",
    "    maxCol = biggestColumn(simMatrix)\n",
    "    return sum(maxCol)/len(maxCol)\n",
    "def getSentenceScore(sentence1, sentence2):\n",
    "    R=executeBertScore(sentence1, sentence2)\n",
    "    S=executeBertScore(sentence2, sentence1)\n",
    "    return 2*(R*S)/(R+S)\n",
    "    \n",
    "\n",
    "## COSINE SIMILARITY between average vectors\n",
    "def getSentenceScorec(sentence1, sentence2):\n",
    "    sentence1=sentence1.lower()\n",
    "    sentence2=sentence2.lower()\n",
    "    sen1List = sentence1.split()\n",
    "    sen2List = sentence2.split()\n",
    "    emb1=[wv[word] for word in sen1List if word in wv]\n",
    "    emb2=[wv[word] for word in sen2List if word in wv]\n",
    "    if len(emb1)==0 or len(emb2)==0:\n",
    "        return 0\n",
    "    emb1 = sum(emb1)/len(emb1)\n",
    "    emb2 = sum(emb2)/len(emb2)\n",
    "    return 1-cosine(emb1, emb2)\n",
    "\n",
    "##Word Movers Distance\n",
    "def getSentenceScorem(sentence1, sentence2):\n",
    "    sentence1=sentence1.lower()\n",
    "    sentence2=sentence2.lower()\n",
    "    sen1List = sentence1.split()\n",
    "    sen2List = sentence2.split()\n",
    "    emb1=[wv[word] for word in sen1List if word in wv]\n",
    "    emb2=[wv[word] for word in sen2List if word in wv]\n",
    "    distance_matrix = cdist(emb1, emb2)\n",
    "\n",
    "    min_distances = np.min(distance_matrix, axis=1)\n",
    "\n",
    "    total_distance = np.sum(min_distances) / len(emb1)\n",
    "\n",
    "    return total_distance\n",
    "\n",
    "##DEBUG\n",
    "sen1=\"This was a series of nested angular standards , so that measurements in azimuth and elevation could be done directly in polar coordinates relative to the ecliptic .\"\n",
    "sen2=\"This was a series of nested polar scales , so that measurements in azimuth and elevation could be performed directly in angular coordinates relative to the ecliptic .\"\n",
    "\n",
    "print(getSentenceScore(sen1, sen2))\n",
    "print(getSentenceScorec(sen1, sen2))\n",
    "print(getSentenceScorem(sen1, sen2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This was a series of nested angular standards , so that measurements in azimuth and elevation could be done directly in polar coordinates relative to the ecliptic .\n",
      "This was a series of nested polar scales , so that measurements in azimuth and elevation could be performed directly in angular coordinates relative to the ecliptic .\n",
      "0.9425530127497206\n",
      "0\n",
      "\n",
      "His father emigrated to Missouri in 1868 but returned when his wife became ill and before the rest of the family could also go to America .\n",
      "His father emigrated to America in 1868 , but returned when his wife became ill and before the rest of the family could go to Missouri .\n",
      "0.9853399498314827\n",
      "0\n",
      "\n",
      "In January 2011 , the Deputy Secretary General of FIBA Asia , Hagop Khajirian , inspected the venue together with SBP - President Manuel V. Pangilinan .\n",
      "In January 2011 , FIBA Asia deputy secretary general Hagop Khajirian along with SBP president Manuel V. Pangilinan inspected the venue .\n",
      "0.952760600929088\n",
      "1\n",
      "\n",
      "Steiner argued that , in the right circumstances , the spiritual world can be explored through direct experience by practicing ethical and cognitive forms of rigorous self-discipline .\n",
      "Steiner held that the spiritual world can be researched in the right circumstances through direct experience , by persons practicing rigorous forms of ethical and cognitive self-discipline .\n",
      "0.9256808998278072\n",
      "0\n",
      "\n",
      "Luciano Williames Dias ( born July 25 , 1970 ) is a Brazilian football coach and former player .\n",
      "Luciano Williames Dias ( born 25 July 1970 ) is a former football coach and Brazilian player .\n",
      "0.9999999933772616\n",
      "0\n",
      "\n",
      "During her sophomore , junior and senior summers , she spent half of it with her Alaska team , and half playing , and living in Oregon .\n",
      "During her second , junior and senior summers , she spent half of it with her Alaska team , half playing and living in Oregon .\n",
      "0.9806318225355033\n",
      "1\n",
      "\n",
      "The smallest number that can be represented in two positive and seventh ways as a sum of four different powers is 2056364173794800 .\n",
      "The smallest number that can be represented as a sum of four positive seventh potences in two different ways is 2056364173794800 .\n",
      "0.9765121502852396\n",
      "0\n",
      "\n",
      "His father emigrated to Missouri in 1868 , but returned when his wife became ill and before the rest of the family could go to America .\n",
      "His father emigrated to Missouri in 1868 but returned when his wife became ill and before the rest of the family could also go to America .\n",
      "0.9853399498314827\n",
      "1\n",
      "\n",
      "The Villa Pesquera facilities are owned by the Municipality of Ponce , but operated by the fishermen themselves .\n",
      "The facilities of Villa Pesquera are operated by the Municipality of Ponce , but are owned by the fishermen .\n",
      "0.9803169161040285\n",
      "0\n",
      "\n",
      "It is situated south of Köroğlu Mountains and to the north of Bolu .\n",
      "It is situated south of Köroğlu - mountains and north of the Bolu .\n",
      "1.0\n",
      "1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cur='test'\n",
    "for i in range(10):\n",
    "    print(dataset[cur][i]['sentence1'])\n",
    "    print(dataset[cur][i]['sentence2'])\n",
    "    print(getSentenceScore(dataset[cur][i]['sentence1'], dataset[cur][i]['sentence2']))\n",
    "    print(dataset[cur][i]['label'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.442\n"
     ]
    }
   ],
   "source": [
    "threshold=0.4\n",
    "correct=0\n",
    "cur='test'\n",
    "for i in range(len(dataset[cur])):\n",
    "    if getSentenceScore(dataset[cur][i]['sentence1'], dataset[cur][i]['sentence2'])>threshold:\n",
    "        if dataset[cur][i]['label']==1:\n",
    "            correct+=1\n",
    "    else:\n",
    "        if dataset[cur][i]['label']==0:\n",
    "            correct+=1\n",
    "print(correct/len(dataset[cur]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def createIdf(cur):\n",
    "    idf={}\n",
    "    for i in range(len(dataset[cur])):\n",
    "        sen1=dataset[cur][i]['sentence1']\n",
    "        sen2=dataset[cur][i]['sentence2']\n",
    "        sen1=sen1.lower()\n",
    "        sen2=sen2.lower()\n",
    "        sen1List = sen1.split()\n",
    "        sen2List = sen2.split()\n",
    "        for word in sen1List:\n",
    "            if word in wv:\n",
    "                if word not in idf:\n",
    "                    idf[word]=1\n",
    "                else:\n",
    "                    idf[word]+=1\n",
    "        for word in sen2List:\n",
    "            if word in wv:\n",
    "                if word not in idf:\n",
    "                    idf[word]=1\n",
    "                else:\n",
    "                    idf[word]+=1\n",
    "    wordNum=0\n",
    "    for word in idf:\n",
    "        wordNum+=1\n",
    "    for word in idf:\n",
    "        idf[word]=math.log(wordNum/idf[word])\n",
    "    return idf\n",
    "\n",
    "def getSentenceScoreWithIdf(sentence1, sentence2, idf):\n",
    "    sentence1=sentence1.lower()\n",
    "    sentence2=sentence2.lower()\n",
    "    simMatrix = sentencesToMatrix(sentence1, sentence2)\n",
    "    maxCol = biggestColumn(simMatrix)\n",
    "    ans=0\n",
    "    curIdf=0\n",
    "    for i in range(len(maxCol)):\n",
    "        sen=sentence1.split()[i]\n",
    "        if sen in idf:\n",
    "            ans+=maxCol[i]*idf[sen] \n",
    "            curIdf+=idf[sen]\n",
    "    # print(curIdf)\n",
    "    if curIdf==0:\n",
    "        return 0\n",
    "    ans/=curIdf\n",
    "    return (ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This was a series of nested angular standards , so that measurements in azimuth and elevation could be done directly in polar coordinates relative to the ecliptic .\n",
      "This was a series of nested polar scales , so that measurements in azimuth and elevation could be performed directly in angular coordinates relative to the ecliptic .\n",
      "0.9349131934486553\n",
      "0\n",
      "\n",
      "His father emigrated to Missouri in 1868 but returned when his wife became ill and before the rest of the family could also go to America .\n",
      "His father emigrated to America in 1868 , but returned when his wife became ill and before the rest of the family could go to Missouri .\n",
      "1.0\n",
      "0\n",
      "\n",
      "In January 2011 , the Deputy Secretary General of FIBA Asia , Hagop Khajirian , inspected the venue together with SBP - President Manuel V. Pangilinan .\n",
      "In January 2011 , FIBA Asia deputy secretary general Hagop Khajirian along with SBP president Manuel V. Pangilinan inspected the venue .\n",
      "0.8547474441366353\n",
      "1\n",
      "\n",
      "Steiner argued that , in the right circumstances , the spiritual world can be explored through direct experience by practicing ethical and cognitive forms of rigorous self-discipline .\n",
      "Steiner held that the spiritual world can be researched in the right circumstances through direct experience , by persons practicing rigorous forms of ethical and cognitive self-discipline .\n",
      "0.9737794560178892\n",
      "0\n",
      "\n",
      "Luciano Williames Dias ( born July 25 , 1970 ) is a Brazilian football coach and former player .\n",
      "Luciano Williames Dias ( born 25 July 1970 ) is a former football coach and Brazilian player .\n",
      "0.9999999679086518\n",
      "0\n",
      "\n",
      "During her sophomore , junior and senior summers , she spent half of it with her Alaska team , and half playing , and living in Oregon .\n",
      "During her second , junior and senior summers , she spent half of it with her Alaska team , half playing and living in Oregon .\n",
      "0.9734817242830902\n",
      "1\n",
      "\n",
      "The smallest number that can be represented in two positive and seventh ways as a sum of four different powers is 2056364173794800 .\n",
      "The smallest number that can be represented as a sum of four positive seventh potences in two different ways is 2056364173794800 .\n",
      "0.9999999774814895\n",
      "0\n",
      "\n",
      "His father emigrated to Missouri in 1868 , but returned when his wife became ill and before the rest of the family could go to America .\n",
      "His father emigrated to Missouri in 1868 but returned when his wife became ill and before the rest of the family could also go to America .\n",
      "1.0\n",
      "1\n",
      "\n",
      "The Villa Pesquera facilities are owned by the Municipality of Ponce , but operated by the fishermen themselves .\n",
      "The facilities of Villa Pesquera are operated by the Municipality of Ponce , but are owned by the fishermen .\n",
      "0.9891666949499356\n",
      "0\n",
      "\n",
      "It is situated south of Köroğlu Mountains and to the north of Bolu .\n",
      "It is situated south of Köroğlu - mountains and north of the Bolu .\n",
      "1.0\n",
      "1\n",
      "\n",
      "The Río Blanco mine is a large copper mine located in the north of Peru in Loreto Region .\n",
      "The Río Blanco - Mine is a large copper mine in northern Peru in the region of Loreto .\n",
      "0.9201268956122001\n",
      "1\n",
      "\n",
      "He appeared as General Tao in the Amazon - Show `` The Man at the High Castle '' , and as Onoda in AMC `` Hell On Wheels '' .\n",
      "He appeared as General Onoda in the Amazon - Show `` The Man in High Castle '' and as Tao on AMCs '' Hell On Wheels '' .\n",
      "1.0164073817288917\n",
      "0\n",
      "\n",
      "The spectral levels of light that can be measured by plants for photosynthesis is similar to , but not the same as what 's used by lumens .\n",
      "The spectral light levels that can be measured by plants for photosynthesis are similar , but not the same as what is used by lumens .\n",
      "1.0000000095645156\n",
      "1\n",
      "\n",
      "The Sunset Sunset Road comes from right and becomes Briscoe Mountain Road .\n",
      "Sunset Road comes in from the right and becomes Briscoe Mountain Road .\n",
      "0.999999998132981\n",
      "1\n",
      "\n",
      "To get there , take the Marine Drive from the Lions Gate Bridge to the West , past Lighthouse Park , Horseshoe Bay and then further on to the 7100 Marine Drive block .\n",
      "To get there , take Marine Drive west from the Lions Gate Bridge past Horseshoe Bay to Lighthouse Park and then continue on to 7100 Block Marine Drive .\n",
      "0.9696717914167821\n",
      "0\n",
      "\n",
      "Inverallan is one of the parishes which formed the ecclesiastical ( later civil ) parish of `` Cromdale , Inverallan and Advie '' in Morayshire in Scotland .\n",
      "Inverallan is one of the parishes that formed the civil ( later ecclesiastical ) parish of Cromdale , Inverallan and Advie in Morayshire , Scotland .\n",
      "1.0214817323098047\n",
      "0\n",
      "\n",
      "Mr. Thuso Nokwanda Mbedu was born in Pietermaritzburg as Thuso Mbebu .\n",
      "Thuso Nokwanda Mbedu was born Thuso Mbebu in Pietermaritzburg .\n",
      "0\n",
      "1\n",
      "\n",
      "For ideal gases , the molar volume is given by the ideal gas equation , a good approximation for many usual gases at standard temperature and pressure .\n",
      "For ideal gases the molar volume is given by the standard gas equation , a good approximation for many common gases at ideal temperature and pressure .\n",
      "0.9341347329787614\n",
      "0\n",
      "\n",
      "John Barrow Island is a member of the Queen Elizabeth Islands and the Canadian Arctic Archipelago in the territory of Nunavut .\n",
      "John Barrow Island is a member of the Canadian Arctic Archipelago and the Queen Elizabeth Islands in the Nunavut area .\n",
      "0.9163376621650091\n",
      "0\n",
      "\n",
      "It was chosen as the 19th best movie at the 7th Yokohama Film Festival .\n",
      "It was chosen as the 7th best film at the 19th Yokohama Film Festival .\n",
      "0.974825037118455\n",
      "0\n",
      "\n",
      "0.476\n"
     ]
    }
   ],
   "source": [
    "cur='test'\n",
    "idf=createIdf(cur)\n",
    "for i in range(20):\n",
    "    print(dataset[cur][i]['sentence1'])\n",
    "    print(dataset[cur][i]['sentence2'])\n",
    "    print(getSentenceScoreWithIdf(dataset[cur][i]['sentence1'], dataset[cur][i]['sentence2'],idf))\n",
    "    print(dataset[cur][i]['label'])\n",
    "    print()\n",
    "\n",
    "threshold=0.95\n",
    "correct=0\n",
    "for i in range(len(dataset[cur])):\n",
    "    score=getSentenceScoreWithIdf(dataset[cur][i]['sentence1'], dataset[cur][i]['sentence2'],idf)\n",
    "    # print(score)\n",
    "    if score>threshold:\n",
    "        if dataset[cur][i]['label']==1:\n",
    "            correct+=1\n",
    "    else:\n",
    "        if dataset[cur][i]['label']==0:\n",
    "            correct+=1\n",
    "print(correct/len(dataset[cur]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
